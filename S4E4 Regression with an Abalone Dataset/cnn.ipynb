{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "## Load Data\n",
    "train = pd.read_csv('data/reduced_new_train.csv', index_col='id')\n",
    "test = pd.read_csv('data/test.csv', index_col='id')\n",
    "\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# append a column of zeros to test data\n",
    "test['Rings'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, data, target_column):\n",
    "        self.data = data.drop(target_column, axis=1)\n",
    "        \n",
    "        # Convert data to float32 dtype for PyTorch and handle non-numeric issues\n",
    "        for col in self.data.columns:\n",
    "            self.data[col] = pd.to_numeric(self.data[col], errors='coerce')  # Coerce errors will convert non-numeric to NaN\n",
    "        \n",
    "        # Fill NaN values with the mean (or median, zero, etc.)\n",
    "        self.data.fillna(self.data.mean(), inplace=True)\n",
    "        \n",
    "        self.targets = data[target_column].astype(float).values  # Ensure target is also float\n",
    "        \n",
    "        # Convert DataFrame to numpy array\n",
    "        self.data = self.data.values.astype(np.float32)\n",
    "        self.targets = self.targets.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.data[idx])  # Now safely convert to tensor\n",
    "        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "train_loader = DataLoader(TabularDataset(train, 'Rings'), batch_size=64, shuffle=True, pin_memory=True)  # pin_memory for faster CPU->GPU transfers\n",
    "val_loader = DataLoader(TabularDataset(val, 'Rings'), batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(TabularDataset(test, 'Rings'), batch_size=64, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNRegressor(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(CNNRegressor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=32, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=1)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)  # Reshape x to [batch_size, num_features, 1] for Conv1D\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Number of features excluding the target\n",
    "num_features = train.shape[1] - 1\n",
    "model = CNNRegressor(num_features=num_features).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_loss(y_pred, y_true):\n",
    "    return torch.sqrt(F.mse_loss(torch.log1p(y_pred), torch.log1p(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1308235079050064\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = rmsle_loss(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.16169371163925608\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = rmsle_loss(outputs.squeeze(), targets)\n",
    "        val_loss.append(loss.item())\n",
    "    \n",
    "    print(f'Validation Loss: {np.mean(val_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "        \n",
    "# save to csv \n",
    "\n",
    "submission = pd.DataFrame({'id': test.index, 'Rings': predictions})\n",
    "submission.to_csv('submissions/cnn1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
