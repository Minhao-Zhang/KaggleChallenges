{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "ORIGINAL_DATA_PATH = DATA_PATH\n",
    "SUBMISSIONS_PATH = './submissions/'\n",
    "MODELS_PATH = './trained_models/'\n",
    "TEMP_PATH = './temp/'\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv(DATA_PATH + 'train.csv', index_col='id')\n",
    "test = pd.read_csv(DATA_PATH + 'test.csv', index_col='id')\n",
    "original = pd.read_csv(ORIGINAL_DATA_PATH + 'flood.csv')\n",
    "original.index.rename('id', inplace=True)\n",
    "new_train = pd.concat([train, original], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hmean, gmean\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "NON_FEATURES = ['id', 'FloodProbability', 'fold']\n",
    "BASE_FEATURES = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors']\n",
    "\n",
    "def add_features(df):\n",
    "    df['total'] = df[BASE_FEATURES].sum(axis=1)\n",
    "    df['amplified_sum'] = (df[BASE_FEATURES] ** 1.5).sum(axis=1)\n",
    "    df['fskew'] = df[BASE_FEATURES].skew(axis=1)\n",
    "    df['fkurtosis'] = df[BASE_FEATURES].kurtosis(axis=1)\n",
    "    df['std'] = df[BASE_FEATURES].std(axis=1)\n",
    "    df['max'] = df[BASE_FEATURES].max(axis=1)\n",
    "    df['min'] = df[BASE_FEATURES].min(axis=1)\n",
    "    df['range'] = df['max'] - df['min']\n",
    "    df['median'] = df[BASE_FEATURES].median(axis=1)\n",
    "    df['ptp'] = df[BASE_FEATURES].values.ptp(axis=1)\n",
    "    df['q25'] = df[BASE_FEATURES].quantile(0.25, axis=1)\n",
    "    df['q75'] = df[BASE_FEATURES].quantile(0.75, axis=1)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "train = add_features(train)\n",
    "FEATURES = [col for col in train.columns if col not in NON_FEATURES]\n",
    "train = train[FEATURES + ['FloodProbability']]\n",
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.sort_values() missing 1 required positional argument: 'by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print correlation sorted by target\u001b[39;00m\n\u001b[1;32m      2\u001b[0m correlation \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[0;32m----> 3\u001b[0m correlation \u001b[38;5;241m=\u001b[39m \u001b[43mcorrelation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(correlation)\n",
      "\u001b[0;31mTypeError\u001b[0m: DataFrame.sort_values() missing 1 required positional argument: 'by'"
     ]
    }
   ],
   "source": [
    "# print correlation sorted by target\n",
    "correlation = train.corr()\n",
    "correlation = correlation['FloodProbability'].sort_values(ascending=False)\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "X = train[FEATURES].values\n",
    "y = train['FloodProbability'].values\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)#.to('cuda')\n",
    "Q = 25\n",
    "U,S,V = torch.pca_lowrank(X, q=Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstuct the dataframe \n",
    "U = U.detach().numpy()\n",
    "X_pca = pd.DataFrame(U, columns=[f'pca_{i}' for i in range(Q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca preds: 0.8642885617977527\n",
      "original preds: 0.8684897199424749\n"
     ]
    }
   ],
   "source": [
    "# split the data to train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_pca, X_val_pca, y_train, y_val = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define the model\n",
    "lgbm_params = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'num_leaves': 227, \n",
    "    'subsample_for_bin': 204195, \n",
    "    'min_child_samples': 98, \n",
    "    'max_depth': 14, \n",
    "    'learning_rate': 0.008725580097840743, \n",
    "    'n_estimators': 1486, \n",
    "    'subsample': 0.6924206162743796, \n",
    "    'colsample_bytree': 0.608985636026134, \n",
    "    'reg_alpha': 0.000982304606619489, \n",
    "    'reg_lambda': 4.733782716082672\n",
    "    }\n",
    "\n",
    "model = LGBMRegressor(device='cuda', verbose=-1)\n",
    "\n",
    "model.fit(X_train_pca, y_train)\n",
    "pca_preds  = model.predict(X_val_pca)\n",
    "print('pca preds:', r2_score(y_val, pca_preds))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_val)\n",
    "print('original preds:', r2_score(y_val, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform the test data\n",
    "# X_test = test[FEATURES].values\n",
    "# X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "# # centerr the data \n",
    "# X_test = X_test - X.mean(0)\n",
    "# # apply the pca\n",
    "# X_test_pca = torch.mm(X_test, V)\n",
    "\n",
    "# model.fit(X_pca, y)\n",
    "# preds = model.predict(X_test_pca)\n",
    "\n",
    "# submission = pd.DataFrame({'id': test.index, 'FloodProbability': preds})\n",
    "# submission.to_csv(SUBMISSIONS_PATH + 'lgbm_pca.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
