{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA of Steel Defect Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_one_fault.csv', index_col='id')\n",
    "test = pd.read_csv('data/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any columns have missing values\n",
    "# print(train.isnull().any())\n",
    "# print(test.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the columns\n",
    "# print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n",
    "y = train[y_columns]\n",
    "X = train.drop(y_columns, axis=1)\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "# print(X.head())\n",
    "# print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test)\n",
    "\n",
    "# undo onehot encoding for y \n",
    "y = y.apply(lambda row: np.argmax(row.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=27)\n",
    "# pca.fit(X)\n",
    "\n",
    "# eigenvalues = pca.explained_variance_\n",
    "# eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# # Create the RFE object and rank each feature\n",
    "# svc = SVC(kernel=\"linear\", C=1)\n",
    "# rfe = RFE(estimator=svc, n_features_to_select=25, step=1)\n",
    "# rfe = rfe.fit(X, y)\n",
    "\n",
    "# # Summarize the selection of the attributes\n",
    "# print(f\"Num Features: {rfe.n_features_}\")\n",
    "# print(f\"Selected Features: {rfe.support_}\")\n",
    "# print(f\"Feature Ranking: {rfe.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 14.0.1.dev0+gba5374836.d20240125 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# models = {\n",
    "#     \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "#     \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "#     \"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "# }\n",
    "\n",
    "# # Perform 5-fold cross-validation and calculate AUC-ROC for each model\n",
    "# cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     # Generate cross-validated estimates for each input data point\n",
    "#     # Method='predict_proba' is used since we need probabilities to calculate AUC-ROC\n",
    "#     y_pred = cross_val_predict(model, X, y, cv=cv, method='predict_proba')\n",
    "    \n",
    "#     # Calculate the AUC-ROC score\n",
    "#     auc_roc = roc_auc_score(y, y_pred, multi_class='ovr', average='macro')\n",
    "    \n",
    "#     print(f\"{name}: AUC-ROC = {auc_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# # Custom GridSearchCV subclass\n",
    "# class CustomGridSearchCV(GridSearchCV):\n",
    "#     def _run_search(self, evaluate_candidates):\n",
    "#         \"\"\"Override the method to print parameter settings.\"\"\"\n",
    "#         def custom_evaluate_candidates(candidate_params):\n",
    "#             for parameters in candidate_params:\n",
    "#                 print(f\"Evaluating: {parameters}\")\n",
    "#                 evaluate_candidates([parameters])\n",
    "                \n",
    "#         super()._run_search(custom_evaluate_candidates)\n",
    "\n",
    "# # Multi-class AUC-ROC scorer\n",
    "# def multiclass_roc_auc_score(y_true, y_pred, average=\"macro\"):\n",
    "#     y_bin = label_binarize(y_true, classes=np.unique(y_true))\n",
    "#     temp = roc_auc_score(y_bin, y_pred, average=average, multi_class='ovr')\n",
    "#     print(temp)\n",
    "#     return temp\n",
    "\n",
    "# # Defining the model\n",
    "# gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# # Setting up the parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 400, 700, 1000],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "#     'max_depth': [3, 4, 5],\n",
    "#     'min_samples_split': [2, 4, 6],\n",
    "#     'min_samples_leaf': [1, 2, 3]\n",
    "# }\n",
    "# # Setting up CustomGridSearchCV with AUC-ROC scoring\n",
    "# auc_roc_scorer = make_scorer(multiclass_roc_auc_score, needs_proba=True)\n",
    "# grid_search = CustomGridSearchCV(estimator=gb, param_grid=param_grid, cv=5, scoring=auc_roc_scorer, n_jobs=-1)\n",
    "\n",
    "# # Fitting CustomGridSearchCV\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Best parameters and best score\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "y_test = rf_model.predict(X_test)\n",
    "output = np.zeros((len(y_test), 7))\n",
    "for i in range(len(y_test)):\n",
    "    output[i, y_test[i]] = 1\n",
    "output = pd.DataFrame(output, columns=y_columns, index=test.index)\n",
    "output.to_csv('submissions/onefault_gbc1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
